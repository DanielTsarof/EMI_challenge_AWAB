{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b209a2e1-7786-4fec-8469-aa0610e7c459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 22:52:38.426690: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-21 22:52:38.434466: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747857158.443443   83937 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747857158.446144   83937 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747857158.454240   83937 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747857158.454249   83937 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747857158.454250   83937 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747857158.454251   83937 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-21 22:52:38.456739: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os, pickle, random, math, glob\n",
    "import numpy as np, pandas as pd, tqdm, torchaudio, torch\n",
    "from transformers import AutoProcessor, HubertModel\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56a50a49-c71e-467e-b695-11e8222c2ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"/media/dtsarev/SatSSD/data\"\n",
    "AUDIO_DIR  = f\"{BASE}/audio\"\n",
    "TRAIN_CSV  = f\"{BASE}/train_split.csv\"\n",
    "VAL_CSV    = f\"{BASE}/valid_split.csv\"\n",
    "EMB_CACHE  = f\"audio_hubert_embeds\"\n",
    "EPOCHS     = 1000\n",
    "os.makedirs(EMB_CACHE, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5442c8c9-dc79-48f1-a2ef-d8f6229e16a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR        = 16_000\n",
    "MAX_SEC   = 12\n",
    "DEVICE    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "EMOS = [\"Admiration\",\"Amusement\",\"Determination\",\"Empathic Pain\",\"Excitement\",\"Joy\"]\n",
    "NUM_EMOS = len(EMOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25727c88-ea69-4f1d-b494-9ce72817c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc  = AutoProcessor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "model = HubertModel.from_pretrained(\"facebook/hubert-large-ls960-ft\").to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_embed(path:str)->np.ndarray:\n",
    "    \"\"\"Return (T, H) HuBERT hidden states for first MAX_SEC seconds of *path* MP3.\"\"\"\n",
    "    wav, sr = torchaudio.load(path)\n",
    "    if sr != SR:\n",
    "        wav = torchaudio.functional.resample(wav, sr, SR)\n",
    "    wav = wav[:, : SR*MAX_SEC]\n",
    "    wav = (wav - wav.mean()) / (wav.std() + 1e-6)  # CMVN\n",
    "    inp = proc(wav.squeeze(), sampling_rate=SR, return_tensors='pt', padding=True)\n",
    "    hid = model(**{k: v.to(DEVICE) for k, v in inp.items()}).last_hidden_state[0]  # (T, 768)\n",
    "    return hid.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea75b395-124d-4ed8-8067-90860b6d64ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train embeds: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8072/8072 [03:55<00:00, 34.25it/s]\n",
      "val embeds: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4588/4588 [02:22<00:00, 32.12it/s]\n"
     ]
    }
   ],
   "source": [
    "def cache_all(csv_path:str, tag:str):\n",
    "    df = pd.read_csv(csv_path, dtype={'Filename': str})\n",
    "    df['Filename'] = df['Filename'].str.zfill(5)\n",
    "    for fn in tqdm(df['Filename'], desc=f\"{tag} embeds\"):\n",
    "        out = f\"{EMB_CACHE}/{tag}_{fn}.npy\"\n",
    "        if os.path.exists(out):\n",
    "            continue\n",
    "        mp3 = f\"{AUDIO_DIR}/{fn}.mp3\"\n",
    "        try:\n",
    "            np.save(out, extract_embed(mp3))\n",
    "        except Exception as e:\n",
    "            print(\"skip\", fn, e)\n",
    "\n",
    "cache_all(TRAIN_CSV, \"train\")\n",
    "cache_all(VAL_CSV,   \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c11e39b8-3642-43b3-8f74-057ab532cc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val shapes: (8072, 4096) (8072, 6) (4588, 4096)\n"
     ]
    }
   ],
   "source": [
    "def build_xy(csv_path:str, tag:str, use_all_stats=True):\n",
    "    df = pd.read_csv(csv_path, dtype={'Filename': str})\n",
    "    df['Filename'] = df['Filename'].str.zfill(5)\n",
    "    X, y = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        fn = row['Filename']\n",
    "        fpath = f\"{EMB_CACHE}/{tag}_{fn}.npy\"\n",
    "        if not os.path.exists(fpath):\n",
    "            continue\n",
    "        feat = np.load(fpath)  # (T, H)\n",
    "        if use_all_stats:\n",
    "            vec = np.concatenate([feat.mean(0), feat.std(0), feat.min(0), feat.max(0)])\n",
    "        else:\n",
    "            vec = feat.mean(0)\n",
    "        X.append(vec)\n",
    "        y.append(row[EMOS].values.astype(np.float32))\n",
    "    return np.stack(X), np.stack(y)\n",
    "\n",
    "X_train, y_train = build_xy(TRAIN_CSV, \"train\", use_all_stats=True)\n",
    "X_val,   y_val   = build_xy(VAL_CSV,   \"val\",   use_all_stats=True)\n",
    "print(\"Train/Val shapes:\", X_train.shape, y_train.shape, X_val.shape)\n",
    "\n",
    "IN_DIM = X_train.shape[1]  # <- used by classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29d3b421-9a32-466b-9ad3-4105bb582819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_loss(preds, targets):\n",
    "    vx, vy = preds - preds.mean(0), targets - targets.mean(0)\n",
    "    corr   = (vx*vy).sum(0) / (torch.sqrt((vx**2).sum(0)*(vy**2).sum(0))+1e-8)\n",
    "    return 1 - corr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "083ed6d0-2578-41dd-87d6-2b7d33d30809",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1: train 0.9983 | val 0.9727\n",
      "  saved best\n",
      "Epoch  2: train 0.9894 | val 0.9714\n",
      "  saved best\n",
      "Epoch  3: train 0.9896 | val 0.9683\n",
      "  saved best\n",
      "Epoch  4: train 0.9917 | val 0.9721\n",
      "Epoch  5: train 0.9746 | val 0.9690\n",
      "Epoch  6: train 0.9664 | val 0.9624\n",
      "  saved best\n",
      "Epoch  7: train 0.9543 | val 0.9575\n",
      "  saved best\n",
      "Epoch  8: train 0.9457 | val 0.9501\n",
      "  saved best\n",
      "Epoch  9: train 0.9318 | val 0.9351\n",
      "  saved best\n",
      "Epoch 10: train 0.9174 | val 0.9181\n",
      "  saved best\n",
      "Epoch 11: train 0.8979 | val 0.8942\n",
      "  saved best\n",
      "Epoch 12: train 0.8811 | val 0.8679\n",
      "  saved best\n",
      "Epoch 13: train 0.8574 | val 0.8409\n",
      "  saved best\n",
      "Epoch 14: train 0.8429 | val 0.8359\n",
      "  saved best\n",
      "Epoch 15: train 0.8353 | val 0.8315\n",
      "  saved best\n",
      "Epoch 16: train 0.8443 | val 0.8418\n",
      "Epoch 17: train 0.8323 | val 0.8064\n",
      "  saved best\n",
      "Epoch 18: train 0.8216 | val 0.7759\n",
      "  saved best\n",
      "Epoch 19: train 0.8061 | val 0.7856\n",
      "Epoch 20: train 0.8088 | val 0.7733\n",
      "  saved best\n",
      "Epoch 21: train 0.8358 | val 0.7881\n",
      "Epoch 22: train 0.8081 | val 0.7565\n",
      "  saved best\n",
      "Epoch 23: train 0.7866 | val 0.7415\n",
      "  saved best\n",
      "Epoch 24: train 0.7808 | val 0.7555\n",
      "Epoch 25: train 0.7668 | val 0.7418\n",
      "Epoch 26: train 0.7823 | val 0.7419\n",
      "Epoch 27: train 0.7660 | val 0.7543\n",
      "Epoch 28: train 0.7639 | val 0.7352\n",
      "  saved best\n",
      "Epoch 29: train 0.7477 | val 0.7554\n",
      "Epoch 30: train 0.7726 | val 0.7832\n",
      "Epoch 31: train 0.7461 | val 0.7410\n",
      "Epoch 32: train 0.7757 | val 0.7461\n",
      "Epoch 33: train 0.7637 | val 0.7228\n",
      "  saved best\n",
      "Epoch 34: train 0.7421 | val 0.7241\n",
      "Epoch 35: train 0.7436 | val 0.7209\n",
      "  saved best\n",
      "Epoch 36: train 0.7286 | val 0.7286\n",
      "Epoch 37: train 0.7293 | val 0.7291\n",
      "Epoch 38: train 0.7400 | val 0.7210\n",
      "Epoch 39: train 0.7364 | val 0.7210\n",
      "Epoch 40: train 0.7265 | val 0.7216\n",
      "Epoch 41: train 0.7320 | val 0.7408\n",
      "Epoch 42: train 0.7318 | val 0.7127\n",
      "  saved best\n",
      "Epoch 43: train 0.7308 | val 0.7256\n",
      "Epoch 44: train 0.7169 | val 0.7341\n",
      "Epoch 45: train 0.7235 | val 0.7091\n",
      "  saved best\n",
      "Epoch 46: train 0.7135 | val 0.7208\n",
      "Epoch 47: train 0.7181 | val 0.7123\n",
      "Epoch 48: train 0.7116 | val 0.7098\n",
      "Epoch 49: train 0.7166 | val 0.7117\n",
      "Epoch 50: train 0.7179 | val 0.7138\n",
      "Epoch 51: train 0.7149 | val 0.7186\n",
      "Epoch 52: train 0.6992 | val 0.7410\n",
      "Early stop\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"2‑layer MLP without output squashing — lets loss drive range.\"\"\"\n",
    "    def __init__(self, in_dim:int, out_dim:int=NUM_EMOS):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(in_dim),\n",
    "            nn.Linear(in_dim, 1024), nn.GELU(), nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),  nn.GELU(), nn.Dropout(0.4),\n",
    "            nn.Linear(512, out_dim)  # **no activation**\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "train_ds = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).float())\n",
    "val_ds   = TensorDataset(torch.from_numpy(X_val).float(),   torch.from_numpy(y_val).float())\n",
    "train_dl = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=256, shuffle=False)\n",
    "\n",
    "model_t = MLP(IN_DIM).to(DEVICE)\n",
    "opt     = torch.optim.AdamW(model_t.parameters(), lr=5e-4, weight_decay=1e-3)\n",
    "# === Pearson correlation loss (optimize metric directly)\n",
    "\n",
    "def pearson_loss(preds, targets):\n",
    "    vx, vy = preds - preds.mean(0), targets - targets.mean(0)\n",
    "    corr = (vx * vy).sum(0) / (torch.sqrt((vx**2).sum(0) * (vy**2).sum(0)) + 1e-8)\n",
    "    return 1 - corr.mean()\n",
    "\n",
    "crit = pearson_loss\n",
    "\n",
    "best, patience, waited = float('inf'), 7, 0\n",
    "for epoch in range(1, EPOCHS):\n",
    "    # --- train\n",
    "    model_t.train(); total=0\n",
    "    for xb, yb in train_dl:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        opt.zero_grad()\n",
    "        pred = model_t(xb)\n",
    "        loss = crit(pred, yb)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model_t.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        total += loss.item()\n",
    "    tloss = total / len(train_dl)\n",
    "\n",
    "    # --- val\n",
    "    model_t.eval(); vtotal=0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_dl:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            vtotal += crit(model_t(xb), yb).item()\n",
    "    vloss = vtotal / len(val_dl)\n",
    "    print(f\"Epoch {epoch:2d}: train {tloss:.4f} | val {vloss:.4f}\")\n",
    "\n",
    "    if vloss < best:\n",
    "        best, waited = vloss, 0\n",
    "        torch.save(model_t.state_dict(), 'best_audio_mlp.pt')\n",
    "        print(\"  saved best\")\n",
    "    else:\n",
    "        waited += 1\n",
    "        if waited >= patience:\n",
    "            print(\"Early stop\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0bb59a6-61df-4a97-be53-3dfa1548d43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Pearson: 0.30535813237021026\n"
     ]
    }
   ],
   "source": [
    "model_t.load_state_dict(torch.load('best_audio_mlp.pt'))\n",
    "model_t.eval(); preds=[]\n",
    "with torch.no_grad():\n",
    "    for xb,_ in val_dl:\n",
    "        preds.append(model_t(xb.to(DEVICE)).cpu())\n",
    "\n",
    "preds = torch.cat(preds).numpy()\n",
    "mean_r = np.mean([np.corrcoef(preds[:,i], y_val[:,i])[0,1] for i in range(NUM_EMOS)])\n",
    "print(\"Macro Pearson:\", mean_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702ede4-f9d0-4af9-823d-4911456164c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
