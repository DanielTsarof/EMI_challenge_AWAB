{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5254b58d-745b-4382-af69-4b54b4dd9098",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from PIL import Image\n",
    "from transformers import Wav2Vec2Model, Wav2Vec2Processor, CLIPTextModel, CLIPTokenizer\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2fdd79-3bb2-45ca-b72b-a8b16f13d9c9",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a448ab16-70a6-4c42-842a-fb3012a9481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Paths\n",
    "BASE_DIR      = \"/media/dtsarev/SatSSD/data\"\n",
    "TRAIN_CSV     = os.path.join(BASE_DIR, \"train_split.csv\")\n",
    "VAL_CSV       = os.path.join(BASE_DIR, \"valid_split.csv\")\n",
    "AUDIO_DIR     = os.path.join(BASE_DIR, \"audio\")\n",
    "IMAGE_DIR     = os.path.join(BASE_DIR, \"face_images\")\n",
    "TEXT_DIR      = os.path.join(BASE_DIR, \"text\")\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE    = 2\n",
    "NUM_EPOCHS    = 20\n",
    "LR            = 1e-4\n",
    "WEIGHT_DECAY  = 1e-5\n",
    "SAVE_EVERY    = 3       # epochs\n",
    "NUM_WORKERS   = 4\n",
    "PIN_MEMORY    = True\n",
    "\n",
    "# Data settings\n",
    "N_FRAMES      = 16      # frames per sample\n",
    "MAX_AUDIO_LEN = 160000  # max waveform length (~10s @16kHz)\n",
    "\n",
    "# Model dims\n",
    "VIS_DIM       = 768\n",
    "AUD_DIM       = 768\n",
    "TXT_DIM       = 512\n",
    "FUSION_DIM    = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a991f0a-e2e4-47e1-89fc-60c43ca8b8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f917a5-261f-40e8-8fa8-6926f7d148d2",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d07ed216-d0b5-4c3e-8235-b572385b28a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class EMIDataset(Dataset):\n",
    "    def __init__(self, csv_file, audio_dir, img_dir, text_dir, transform=None, wav_model=\"facebook/wav2vec2-base-960h\"):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        emo = ['Admiration','Amusement','Determination',\n",
    "               'Empathic Pain','Excitement','Joy']\n",
    "        # force floats, drop rows with NaN\n",
    "        df[emo] = df[emo].apply(pd.to_numeric, errors='coerce')\n",
    "        df = df.dropna(subset=emo).reset_index(drop=True)\n",
    "        self.df = df\n",
    "        self.audio_dir = audio_dir\n",
    "        self.img_dir = img_dir\n",
    "        self.text_dir = text_dir\n",
    "        self.transform = transform or T.Compose([\n",
    "            T.Resize((224,224)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "        ])\n",
    "        self.wav_processor = Wav2Vec2Processor.from_pretrained(wav_model)\n",
    "        self.txt_tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        fname = f\"{int(row['Filename']):05d}\"\n",
    "\n",
    "        # --- Visual frames with fallback ---\n",
    "        folder = os.path.join(self.img_dir, fname)\n",
    "        imgs = []\n",
    "        if os.path.isdir(folder):\n",
    "            files = [f for f in os.listdir(folder) if f.lower().endswith(\".jpg\")]\n",
    "            files = sorted(files)\n",
    "        else:\n",
    "            files = []\n",
    "\n",
    "        if len(files) == 0:\n",
    "            # no frames: use zeros\n",
    "            for _ in range(N_FRAMES):\n",
    "                imgs.append(torch.zeros(3,224,224))\n",
    "        else:\n",
    "            if len(files) >= N_FRAMES:\n",
    "                idxs = np.linspace(0, len(files)-1, N_FRAMES, dtype=int)\n",
    "            else:\n",
    "                idxs = list(range(len(files))) + [len(files)-1] * (N_FRAMES - len(files))\n",
    "            for i in idxs:\n",
    "                img_path = os.path.join(folder, files[i])\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                imgs.append(self.transform(img))\n",
    "        visual = torch.stack(imgs)  # [T,3,224,224]\n",
    "\n",
    "        # --- Audio (unchanged) ---\n",
    "        wav, sr = torchaudio.load(os.path.join(self.audio_dir, f\"{fname}.mp3\"))\n",
    "        wav = wav.mean(0, keepdim=True)\n",
    "        # trim/pad waveform\n",
    "        if wav.shape[1] > MAX_AUDIO_LEN:\n",
    "            wav = wav[:, :MAX_AUDIO_LEN]\n",
    "        else:\n",
    "            wav = nn.functional.pad(wav, (0, MAX_AUDIO_LEN - wav.shape[1]))\n",
    "\n",
    "        # **IMPORTANT**: pass a list of arrays\n",
    "        wav_np = wav.squeeze(0).numpy()   # shape [MAX_AUDIO_LEN]\n",
    "        proc = self.wav_processor(\n",
    "            [wav_np],                       # <-- note the list\n",
    "            sampling_rate=sr,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"longest\",\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        # now proc.input_values shape [1, seq_len], attention_mask [1, seq_len]\n",
    "        audio_values = proc.input_values[0]     # [seq_len]\n",
    "        audio_mask   = proc.attention_mask[0]   # [seq_len]\n",
    "\n",
    "        # --- Text (unchanged) ---\n",
    "        txt = open(os.path.join(self.text_dir, f\"{fname}.txt\")).read().strip()\n",
    "        if len(txt)==0:\n",
    "            txt = \"neutral\"\n",
    "        toks = self.txt_tokenizer(txt, return_tensors=\"pt\", padding=\"max_length\", truncation=True)\n",
    "        input_ids = toks.input_ids.squeeze(0)\n",
    "        attn_mask = toks.attention_mask.squeeze(0)\n",
    "\n",
    "        # --- Labels ---\n",
    "        labels = torch.tensor([\n",
    "            row['Admiration'], row['Amusement'], row['Determination'],\n",
    "            row['Empathic Pain'], row['Excitement'], row['Joy']\n",
    "        ], dtype=torch.float32)\n",
    "        assert not torch.isnan(labels).any(), f\"NaN in labels row {idx}\"\n",
    "\n",
    "        return {\"visual\": visual, \"audio_values\": audio_values, \"audio_mask\": audio_mask, \"input_ids\": input_ids, \"attn_mask\": attn_mask, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1c6b51-d42a-4b3d-a1e8-d0752b38dcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "train_ds = EMIDataset(TRAIN_CSV, AUDIO_DIR, IMAGE_DIR, TEXT_DIR)\n",
    "val_ds   = EMIDataset(VAL_CSV,   AUDIO_DIR, IMAGE_DIR, TEXT_DIR)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886c3c18-baa7-403d-8b3c-7d7891b606fd",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d58b2c-5feb-406e-93da-81faf3d44eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMIModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # (backbones and temporal modules unchanged) â€¦\n",
    "        self.vis_backbone = torchvision.models.vit_b_16(pretrained=True)\n",
    "        self.vis_backbone.heads = nn.Identity()\n",
    "        self.aud_backbone = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "        self.txt_backbone = CLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "        vis_layer = nn.TransformerEncoderLayer(d_model=VIS_DIM, nhead=8)\n",
    "        self.vis_temp = nn.TransformerEncoder(vis_layer, num_layers=2)\n",
    "        aud_layer = nn.TransformerEncoderLayer(d_model=AUD_DIM, nhead=8)\n",
    "        self.aud_temp = nn.TransformerEncoder(aud_layer, num_layers=2)\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(VIS_DIM + AUD_DIM + TXT_DIM, FUSION_DIM),\n",
    "            nn.ReLU(), nn.Dropout(0.3)\n",
    "        )\n",
    "        self.head = nn.Sequential(nn.Linear(FUSION_DIM, 6), nn.Sigmoid())\n",
    "\n",
    "    def forward(self,\n",
    "                visual,        # [B, T, 3, 224,224]\n",
    "                audio_values,  # [B, seq_len]\n",
    "                audio_mask,    # [B, seq_len]\n",
    "                input_ids,     # [B, L]\n",
    "                attn_mask      # [B, L]\n",
    "               ):\n",
    "        bs = visual.size(0)\n",
    "\n",
    "        # Visual stream\n",
    "        v = visual.view(-1,3,224,224)\n",
    "        v_feat = self.vis_backbone(v)                        # [B*T, VIS_DIM]\n",
    "        v_seq  = v_feat.view(bs, N_FRAMES, -1).permute(1,0,2) # [T, B, VIS_DIM]\n",
    "        v_out  = self.vis_temp(v_seq).mean(0)                 # [B, VIS_DIM]\n",
    "\n",
    "        # Audio stream (with mask)\n",
    "        a_feats = self.aud_backbone(\n",
    "            input_values=audio_values,       # [bs, seq_len]\n",
    "            attention_mask=audio_mask        # [bs, seq_len]\n",
    "        ).last_hidden_state                 # [bs, L, AUD_DIM]\n",
    "        a_seq   = a_feats.permute(1,0,2)    # [L, bs, AUD_DIM]\n",
    "        a_out   = self.aud_temp(a_seq).mean(0)  # [bs, AUD_DIM]\n",
    "\n",
    "        # Text stream\n",
    "        t_out = self.txt_backbone(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attn_mask\n",
    "        ).pooler_output                                     # [B, TXT_DIM]\n",
    "        \n",
    "        # debug checks\n",
    "        if torch.isnan(v_out).any():\n",
    "            raise ValueError(\"v_out has NaNs\")\n",
    "        if torch.isnan(a_out).any():\n",
    "            raise ValueError(\"NaNs in a_out\")\n",
    "        if torch.isnan(t_out).any():\n",
    "            raise ValueError(\"t_out has NaNs\")\n",
    "\n",
    "        # Fusion & prediction\n",
    "        x = torch.cat([v_out, a_out, t_out], dim=1)        # [B, sum_dims]\n",
    "        x = self.fusion(x)                                 # [B, FUSION_DIM]\n",
    "        return self.head(x)                                # [B, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03693bfc-6272-4154-bed6-f41c647d1c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# instantiate\n",
    "model = EMIModel().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4df28f-c114-4a1b-a694-4ac121f486f8",
   "metadata": {},
   "source": [
    "### Trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "245db489-d045-4d4e-b431-4161fb0640f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "def pearson_corr(preds, targets):\n",
    "    preds = preds.detach().cpu()\n",
    "    targets = targets.detach().cpu()\n",
    "    vx = preds - preds.mean(0)\n",
    "    vy = targets - targets.mean(0)\n",
    "    corr = (vx*vy).sum(0) / (torch.sqrt((vx**2).sum(0) * (vy**2).sum(0)) + 1e-8)\n",
    "    return corr.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5be3e184-9ddb-4548-9577-ed704da58e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=5e-5,\n",
    "    total_steps=NUM_EPOCHS * len(train_loader),\n",
    "    pct_start=0.1,\n",
    "    div_factor=100,\n",
    "    final_div_factor=1e4,\n",
    "    anneal_strategy=\"cos\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9a7ca3a-eb79-41e2-9f24-768be5a68b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        visual      = batch[\"visual\"].to(DEVICE)         # [B,T,3,224,224]\n",
    "        audio_vals  = batch[\"audio_values\"].to(DEVICE)   # [B, seq_len]\n",
    "        audio_mask  = batch[\"audio_mask\"].to(DEVICE)     # [B, seq_len]\n",
    "        input_ids   = batch[\"input_ids\"].to(DEVICE)      # [B, L]\n",
    "        attn_mask   = batch[\"attn_mask\"].to(DEVICE)      # [B, L]\n",
    "        labels      = batch[\"labels\"].to(DEVICE)         # [B, 6]\n",
    "\n",
    "        preds = model(visual, audio_vals, audio_mask, input_ids, attn_mask)\n",
    "        loss  = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "        total_loss += loss.item() * visual.size(0)\n",
    "        #print(f'{loss} | {preds} | {labels}')\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_corr = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Validation\"):\n",
    "            visual     = batch[\"visual\"].to(DEVICE)\n",
    "            audio_vals = batch[\"audio_values\"].to(DEVICE)\n",
    "            audio_mask  = batch[\"audio_mask\"].to(DEVICE)\n",
    "            input_ids  = batch[\"input_ids\"].to(DEVICE)\n",
    "            attn_mask  = batch[\"attn_mask\"].to(DEVICE)\n",
    "            labels     = batch[\"labels\"].to(DEVICE)\n",
    "\n",
    "            preds = model(visual, audio_vals, audio_mask, input_ids, attn_mask)\n",
    "            loss  = criterion(preds, labels)\n",
    "            total_loss += loss.item() * visual.size(0)\n",
    "            total_corr += pearson_corr(preds, labels) * visual.size(0)\n",
    "    return total_loss / len(loader.dataset), total_corr / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36dc2320-1dfb-4126-9dd0-3d471f08db57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6b83f194284cd2b79b4daab0acf791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/4036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32df8fb4d8e3497dbe38d984c4312993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/2294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 0.0425 | Val Loss: 0.0333 | Val Pearson: 0.1434\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f141caaa0734a4ab733c0f4499ee04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/4036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61665fff142842bda941e7ba8e4a5252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/2294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 | Train Loss: 0.0336 | Val Loss: 0.0319 | Val Pearson: 0.1557\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2206947087724f109be91e1ab871958f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/4036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43ddacd7e034471a5d12ccae97c3741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/2294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      " Exception ignored in:   <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80> \n",
      " Traceback (most recent call last):\n",
      "   File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "     ^self._shutdown_workers()\n",
      "^  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "^    ^^if w.is_alive():^\n",
      "^^ ^ ^ ^^ \n",
      "   File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "      assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "^ ^^ ^ ^ ^   ^^ ^ ^ ^ ^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      " ^ ^ ^^  ^ ^^ ^^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^AssertionError^: ^can only test a child process^\n",
      "^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 | Train Loss: 0.0295 | Val Loss: 0.0327 | Val Pearson: 0.1606\n",
      "Saved checkpoint: emi_epoch_3.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48abddce285740f09ab33c8969109301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/4036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00be72945f934227b592e2b37f9bdf23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/2294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 | Train Loss: 0.0259 | Val Loss: 0.0322 | Val Pearson: 0.1675\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fa6476b33a4521a1523f9b12610373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/4036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1646, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fac99a2ff6443d7bc73692795ef9776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/2294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 | Train Loss: 0.0223 | Val Loss: 0.0334 | Val Pearson: 0.1638\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a0c17fb219410abb8aaa68495f3653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/4036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e76abfd6e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dtsarev/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1627, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 930, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/dtsarev/anaconda3/lib/python3.11/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, NUM_EPOCHS+\u001b[32m1\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     train_loss = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     val_loss, val_corr = validate(model, val_loader, criterion)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUM_EPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVal Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVal Pearson: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_corr\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, loader, criterion, optimizer)\u001b[39m\n\u001b[32m      2\u001b[39m model.train()\n\u001b[32m      3\u001b[39m total_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTraining\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvisual\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvisual\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# [B,T,3,224,224]\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43maudio_vals\u001b[49m\u001b[43m  \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio_values\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# [B, seq_len]\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/tqdm/notebook.py:250\u001b[39m, in \u001b[36mtqdm_notebook.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    249\u001b[39m     it = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__iter__\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1443\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1441\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1442\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1443\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1444\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1445\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/master_of_cv/DIPLOM/repos/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1284\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1272\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1281\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1285\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1287\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1288\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/queue.py:180\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    178\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    179\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m item = \u001b[38;5;28mself\u001b[39m._get()\n\u001b[32m    182\u001b[39m \u001b[38;5;28mself\u001b[39m.not_full.notify()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/threading.py:324\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    326\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_corr = validate(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{NUM_EPOCHS} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | \"\n",
    "          f\"Val Pearson: {val_corr:.4f}\")\n",
    "\n",
    "    if epoch % SAVE_EVERY == 0:\n",
    "        ckpt = f\"emi_epoch_{epoch}.pth\"\n",
    "        torch.save(model.state_dict(), ckpt)\n",
    "        print(f\"Saved checkpoint: {ckpt}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fd78ad-4ffd-49f9-88ed-5079637fa835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
